{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d28673b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from transformers import pipeline, TrainingArguments, AutoModel, AutoModelForSequenceClassification, Trainer, ElectraTokenizer\n",
    "from datasets import load_dataset, ClassLabel\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from umap import UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f44cb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "if torch.mps.is_available():\n",
    "    device = torch.device('mps:0')\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2830d45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess csv files\n",
    "\n",
    "df1 = pd.read_csv('data/한국어_단발성_대화_데이터셋.csv')\n",
    "df2 = pd.read_csv('data/감정 분류를 위한 대화 음성 데이터셋.csv')\n",
    "df = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "df = df.dropna(subset=['emotion'])\n",
    "df.loc[df['emotion'].isin(['happiness']), 'emotion'] = '행복'\n",
    "df.loc[df['emotion'].isin(['neutral']), 'emotion'] = '중립'\n",
    "df.loc[df['emotion'].isin(['sadness']), 'emotion'] = '슬픔'\n",
    "df.loc[df['emotion'].isin(['angry']), 'emotion'] = '분노'\n",
    "df.loc[df['emotion'].isin(['surprise']), 'emotion'] = '놀람'\n",
    "df.loc[df['emotion'].isin(['disgust']), 'emotion'] = '혐오'\n",
    "df.loc[df['emotion'].isin(['fear']), 'emotion'] = '공포'\n",
    "\n",
    "emotion_names = df['emotion'].unique()\n",
    "df['label'] = df['emotion'].apply(lambda x: emotion_names.tolist().index(x))\n",
    "df = df.drop('emotion', axis=1)\n",
    "df.to_csv('data/processed_emotion_data.csv', index=False)\n",
    "emotion_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0602339d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "emotions_local = load_dataset('csv', data_files='data/processed_emotion_data.csv')\n",
    "class_label = ClassLabel(num_classes=len(emotion_names), names=emotion_names.tolist())\n",
    "emotions = emotions_local.cast_column('label', class_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f74e31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import emoji\n",
    "from soynlp.normalizer import repeat_normalize\n",
    "\n",
    "emojis = ''.join(emoji.EMOJI_DATA.keys())\n",
    "pattern = re.compile(f'[^ .,?!/@$%~％·∼()\\x00-\\x7Fㄱ-ㅣ가-힣{emojis}]+')\n",
    "url_pattern = re.compile(\n",
    "    r'https?:\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b([-a-zA-Z0-9()@:%_\\+.~#?&//=]*)')\n",
    "\n",
    "import re\n",
    "import emoji\n",
    "from soynlp.normalizer import repeat_normalize\n",
    "\n",
    "pattern = re.compile(f'[^ .,?!/@$%~％·∼()\\x00-\\x7Fㄱ-ㅣ가-힣]+')\n",
    "url_pattern = re.compile(\n",
    "    r'https?:\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b([-a-zA-Z0-9()@:%_\\+.~#?&//=]*)')\n",
    "\n",
    "def clean(x): \n",
    "    x = pattern.sub(' ', x)\n",
    "    x = emoji.replace_emoji(x, replace='') #emoji 삭제\n",
    "    x = url_pattern.sub('', x)\n",
    "    x = x.strip()\n",
    "    x = repeat_normalize(x, num_repeats=2)\n",
    "    return x\n",
    "\n",
    "emotions = emotions.map(lambda x: {'text': [clean(t) for t in x['text']]}, batched=True, batch_size=None)\n",
    "emotions = emotions.filter(lambda x: len(x['text'].split()) > 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5505086",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions = emotions[\"train\"].train_test_split(test_size=0.2, seed=42)\n",
    "labels = emotions['train'].features['label'].names\n",
    "\n",
    "train_ds = emotions['train']\n",
    "emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ea3a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check frequency of classes\n",
    "emotions.set_format(type=\"pandas\")\n",
    "df = emotions['train'][:]\n",
    "\n",
    "def label_int2str(row):\n",
    "    return emotions['train'].features['label'].int2str(row)\n",
    "\n",
    "df['label_name'] = df['label'].apply(label_int2str)\n",
    "\n",
    "matplotlib.rc('font', family='Malgun Gothic')\n",
    "matplotlib.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "df['label_name'].value_counts(ascending=True).plot.barh()\n",
    "plt.title('Frequency of Classes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1735860c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# context size\n",
    "df['Words Per Sentence'] = df['text'].str.split().apply(len)\n",
    "df.boxplot('Words Per Sentence', by='label_name', grid = False, showfliers = False, color = 'black')\n",
    "plt.suptitle('')\n",
    "plt.xlabel('')\n",
    "plt.show()\n",
    "\n",
    "emotions.reset_format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7186f0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ckpt = \"monologg/koelectra-base-v3-discriminator\"\n",
    "tokenizer = ElectraTokenizer.from_pretrained(model_ckpt)\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"text\"], padding=True, truncation=True)\n",
    "\n",
    "emotions_encoded = emotions.map(tokenize, batched = True, batch_size=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91dc88c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModel.from_pretrained(model_ckpt).to(device)\n",
    "\n",
    "def extract_hidden_states(batch):\n",
    "    inputs = {k:v.to(device) for k, v in batch.items() if k in tokenizer.model_input_names}\n",
    "    with torch.no_grad():\n",
    "        last_hidden_state = model(**inputs).last_hidden_state\n",
    "    return {\"hidden_state\": last_hidden_state[:, 0].cpu().numpy()}\n",
    "\n",
    "emotions_encoded.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "emotions_hidden=emotions_encoded.map(extract_hidden_states, batched = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca34504",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(emotions_hidden['train']['hidden_state'])\n",
    "x_test = np.array(emotions_hidden['test']['hidden_state'])\n",
    "y_train = np.array(emotions_hidden['train']['label'])\n",
    "y_test = np.array(emotions_hidden['test']['label'])\n",
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ee69f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_scaled = MinMaxScaler().fit_transform(x_train)\n",
    "mapper = UMAP(n_components=2, metric='cosine').fit(x_scaled)\n",
    "df_emb = pd.DataFrame(mapper.embedding_, columns = [\"X\", \"Y\"])\n",
    "df_emb['label'] = y_train\n",
    "df_emb.head()\n",
    "\n",
    "fig, axes = plt.subplots(3, 3, figsize=(7, 5))\n",
    "axes = axes.flatten()\n",
    "cmaps = ['Greys', 'Blues', 'Oranges', 'Reds', \"Purples\", 'Greens', 'Grays']\n",
    "labels = emotions['train'].features['label'].names\n",
    "\n",
    "for i, (label, cmap) in enumerate(zip(labels, cmaps)):\n",
    "    df_emb_sub = df_emb.query(f'label == {i}')\n",
    "    axes[i].hexbin(df_emb_sub['X'], df_emb_sub['Y'], cmap=cmap, gridsize=20, linewidths=(0,))\n",
    "    axes[i].set_title(label)\n",
    "    axes[i].set_xticks([]), axes[i].set_yticks([])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6128f26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels=len(emotion_names)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_ckpt, num_labels=num_labels).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70ad8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    f1 = f1_score(labels, preds, average = 'weighted')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00ee373",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "logging_steps = (len(emotions_encoded['train']) // batch_size)\n",
    "model_name = 'koelectra-base-v3-finetuned-emotion'\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=model_name,\n",
    "    num_train_epochs=4,\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy='epoch',\n",
    "    disable_tqdm=False,\n",
    "    logging_steps=logging_steps,\n",
    "    push_to_hub=True,\n",
    "    save_strategy='epoch',\n",
    "    metric_for_best_model=\"f1\",\n",
    "    greater_is_better=True,\n",
    "    load_best_model_at_end=True,\n",
    "    log_level='error'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033d77ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model = model, args = training_args,\n",
    "                  compute_metrics = compute_metrics,\n",
    "                  train_dataset=emotions_encoded['train'],\n",
    "                  eval_dataset=emotions_encoded['test'],\n",
    "                  tokenizer=tokenizer)\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "trainer.push_to_hub(commit_message = \"combined two dataset test(conversation, discrete)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bcf8444",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_output = trainer.predict(emotions_encoded['test'])\n",
    "preds_output.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a253bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_preds, y_true, labels):\n",
    "    cm = confusion_matrix(y_true, y_preds, normalize='true')\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "    disp.plot(cmap='Blues', values_format='.2f', ax=ax, colorbar=False)\n",
    "    plt.title('Normalized confusion matrix')\n",
    "    plt.show()\n",
    "\n",
    "y_preds = np.argmax(preds_output.predictions, axis=1)\n",
    "plot_confusion_matrix(y_preds, y_test, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd875f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import cross_entropy\n",
    "\n",
    "def forward_pass_with_label(batch):\n",
    "    inputs = {k:v.to(device) for k, v in batch.items() if k in tokenizer.model_input_names}\n",
    "    with torch.no_grad():\n",
    "        output = model(**inputs)\n",
    "        pred_label = torch.argmax(output.logits, axis=-1)\n",
    "        loss = cross_entropy(output.logits, batch['label'].to(device), reduction='none')\n",
    "    return {'loss': loss.cpu().numpy(), 'predicted_label': pred_label.cpu().numpy()}\n",
    "\n",
    "emotions_encoded.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "emotions_encoded['test'] = emotions_encoded['test'].map(forward_pass_with_label, batched=True, batch_size=16)\n",
    "\n",
    "emotions_encoded.set_format('pandas')\n",
    "cols = ['text', 'label', 'predicted_label', 'loss']\n",
    "df_test = emotions_encoded['test'][:][cols]\n",
    "df_test['label'] = df_test['label'].apply(label_int2str)\n",
    "df_test['predicted_label'] = df_test['predicted_label'].apply(label_int2str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29937091",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.sort_values('loss', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74c2db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.sort_values('loss', ascending=True).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3651aea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, ElectraTokenizer\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "matplotlib.rc('font', family='Malgun Gothic')\n",
    "matplotlib.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "model_id = \"daniel604/koelectra-base-v3-finetuned-emotion\"\n",
    "model_ckpt = \"monologg/koelectra-base-v3-discriminator\"\n",
    "tokenizer = ElectraTokenizer.from_pretrained(model_ckpt)\n",
    "classifier = pipeline(\"text-classification\", model=model_id, tokenizer=tokenizer)\n",
    "\n",
    "def predict(text):\n",
    "    preds = classifier(text, return_all_scores=True)\n",
    "    preds_df = pd.DataFrame(preds[0])\n",
    "    plt.bar(labels, 100 * preds_df['score'], color = 'C0')\n",
    "    plt.title(f'\"{text}\"')\n",
    "    plt.ylabel(\"Class probability (%)\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff147029",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_text = '미치도록 사랑했던 지겹도록 다투었던'\n",
    "predict(custom_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KoBERT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
